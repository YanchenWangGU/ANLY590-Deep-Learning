{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/FrankWang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.3686 - val_loss: 0.3306\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.3211 - val_loss: 0.3169\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.3116 - val_loss: 0.3103\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.3062 - val_loss: 0.3056\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.3034 - val_loss: 0.3038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3e6bbc88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose 5 random images in the testset and comapre them \n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "index = np.random.randint(10000, size=5)\n",
    "f, axarr = plt.subplots(2, 5)\n",
    "for i in range(5):\n",
    "    axarr[0,i].imshow(x_test[index[i]].reshape(28, 28))\n",
    "    axarr[0,i].get_xaxis().set_visible(False)\n",
    "    axarr[0,i].get_yaxis().set_visible(False)\n",
    "    axarr[1,i].imshow(decoded_imgs[index[i]].reshape(28, 28))\n",
    "    axarr[1,i].get_xaxis().set_visible(False)\n",
    "    axarr[1,i].get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Deep CNN\n",
    "Descroption of architectural choices: number of kernels: 32, kernel size: 3 by 3, strides: 2, padding: \"same\", which results in padding the input such that the output has the same length as the original input (reference: https://keras.io/layers/convolutional/), <br />\n",
    "Network depth: two convolution layers $\\rightarrow$ max pooling $\\rightarrow$ 1 dense layer $\\rightarrow$ final output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "#more reshaping\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#set number of categories\n",
    "num_category = 10\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_category)\n",
    "y_test = keras.utils.to_categorical(y_test, num_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten\n",
    "import keras\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 padding=\"same\",\n",
    "                 activation='relu',\n",
    "                 strides=(2, 2),\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding=\"same\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 33s 546us/step - loss: 0.7173 - acc: 0.7395 - val_loss: 0.5217 - val_acc: 0.7996\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 36s 604us/step - loss: 0.4383 - acc: 0.8423 - val_loss: 0.3798 - val_acc: 0.8637\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 34s 570us/step - loss: 0.3820 - acc: 0.8630 - val_loss: 0.4261 - val_acc: 0.8320\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 35s 578us/step - loss: 0.3481 - acc: 0.8724 - val_loss: 0.3393 - val_acc: 0.8745\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 33s 545us/step - loss: 0.3228 - acc: 0.8831 - val_loss: 0.3159 - val_acc: 0.8818\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 34s 571us/step - loss: 0.3050 - acc: 0.8875 - val_loss: 0.2903 - val_acc: 0.8935\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 31s 519us/step - loss: 0.2900 - acc: 0.8944 - val_loss: 0.2946 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 31s 518us/step - loss: 0.2769 - acc: 0.8986 - val_loss: 0.2706 - val_acc: 0.9006\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.2652 - acc: 0.9025 - val_loss: 0.2742 - val_acc: 0.8992\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 29s 480us/step - loss: 0.2552 - acc: 0.9058 - val_loss: 0.2598 - val_acc: 0.9047\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_epoch = 10\n",
    "#model training\n",
    "model_log = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2597639069914818\n",
      "Test accuracy: 0.9047\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.20878062274456025\n",
      "Training accuracy: 0.9236\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Training loss:', score[0]) \n",
    "print('Training accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 645s 11ms/step - loss: 1.6333 - acc: 0.5282 - val_loss: 0.7129 - val_acc: 0.7374\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 625s 10ms/step - loss: 0.9687 - acc: 0.6558 - val_loss: 0.6394 - val_acc: 0.7594\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 706s 12ms/step - loss: 0.8596 - acc: 0.6919 - val_loss: 0.6178 - val_acc: 0.7829\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 723s 12ms/step - loss: 0.8071 - acc: 0.7097 - val_loss: 0.5891 - val_acc: 0.7921\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 647s 11ms/step - loss: 0.7478 - acc: 0.7290 - val_loss: 0.5621 - val_acc: 0.7975\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# loading the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "num_category = 10\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_category)\n",
    "y_test = keras.utils.to_categorical(y_test, num_category)\n",
    "# converting it to RGB\n",
    "x_train = [cv2.cvtColor(cv2.resize(i, (32,32)), cv2.COLOR_GRAY2BGR) for i in x_train]\n",
    "x_train = np.concatenate([arr[np.newaxis] for arr in x_train]).astype('float32')\n",
    "\n",
    "x_test = [cv2.cvtColor(cv2.resize(i, (32,32)), cv2.COLOR_GRAY2BGR) for i in x_test]\n",
    "x_test = np.concatenate([arr[np.newaxis] for arr in x_test]).astype('float32')\n",
    "conv_base = VGG16(weights='imagenet', include_top=False,input_shape = (32,32,3))\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Dropout(0.25))\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "model.add(Flatten())\n",
    "#fully connected to get all relevant data\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "#one more dropout for convergence' sake :) \n",
    "model.add(Dropout(0.5))\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "num_epoch = 5\n",
    "#model training\n",
    "model_log = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5620787094116211\n",
      "Test accuracy: 0.7975\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5212618622144063\n",
      "Training accuracy: 0.8122833333333334\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Training loss:', score[0]) \n",
    "print('Training accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Text Classification\n",
    "## 3.1 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 41\n",
      "Train on 47117 samples, validate on 20194 samples\n",
      "Epoch 1/5\n",
      "47117/47117 [==============================] - 73s 2ms/step - loss: 0.1133 - acc: 0.9803 - val_loss: 0.0923 - val_acc: 0.9815\n",
      "Epoch 2/5\n",
      "47117/47117 [==============================] - 74s 2ms/step - loss: 0.0968 - acc: 0.9804 - val_loss: 0.0921 - val_acc: 0.9815\n",
      "Epoch 3/5\n",
      "47117/47117 [==============================] - 70s 1ms/step - loss: 0.0968 - acc: 0.9804 - val_loss: 0.0922 - val_acc: 0.9815\n",
      "Epoch 4/5\n",
      "47117/47117 [==============================] - 69s 1ms/step - loss: 0.0968 - acc: 0.9804 - val_loss: 0.0927 - val_acc: 0.9815\n",
      "Epoch 5/5\n",
      "47117/47117 [==============================] - 81s 2ms/step - loss: 0.0967 - acc: 0.9804 - val_loss: 0.0920 - val_acc: 0.9815\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "import io\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing import sequence\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.embeddings import Embedding\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "benign = get_file('benign',\n",
    "    origin='https://s3.amazonaws.com/anly-590/url-classification/benign-urls.txt')\n",
    "\n",
    "with io.open(benign, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "benign_srt = []\n",
    "for i in lines:\n",
    "    if i[0]!='#':\n",
    "        i = i.rstrip(\"\\n\\r\")\n",
    "        benign_srt.append(i.lower()) \n",
    "\n",
    "len(benign_srt)\n",
    "\n",
    "malicious = get_file('malicious',\n",
    "    origin='https://s3.amazonaws.com/anly-590/url-classification/malicious-urls.txt')\n",
    "\n",
    "with io.open(malicious, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "malicious_srt = []\n",
    "for i in lines:\n",
    "    if i[0]!='#':\n",
    "        i = i.rstrip(\"\\n\\r\")\n",
    "        malicious_srt.append(i.lower()) \n",
    "        \n",
    "len(malicious_srt)\n",
    "\n",
    "\n",
    "tot_str = benign_srt+malicious_srt\n",
    "\n",
    "my_lst_str = ''.join(map(str, tot_str))\n",
    "\n",
    "\n",
    "chars = sorted(list(set(my_lst_str)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "max_len = max([len(i) for i in tot_str])\n",
    "\n",
    "\n",
    "X = np.zeros((len(tot_str), max_len, len(chars)), dtype=np.uint8 )\n",
    "Y = np.concatenate([np.zeros(len(benign_srt)), np.ones(len(malicious_srt)) ])\n",
    "for i, seq in enumerate(tot_str):\n",
    "    for t, char in enumerate(seq):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "\n",
    "# Test train split\n",
    "rand_index = random.sample(range(len(Y)), len(Y))\n",
    "X_shuffle = X[rand_index]\n",
    "Y_shuffle = Y[rand_index]\n",
    "split_index = int(len(Y)*0.7)\n",
    "X_train = X_shuffle[:split_index,:].astype(int)\n",
    "Y_train = Y_shuffle[:split_index,].astype(int)\n",
    "X_test = X_shuffle[split_index:,:].astype(int)\n",
    "Y_test = Y_shuffle[split_index:,].astype(int)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(128, input_shape=(max_len, len(chars))))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_log = model1.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.09650032298702788\n",
      "Training accuracy: 0.9804104675594796\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_train, Y_train, verbose=0)\n",
    "print('Training loss:', score[0]) \n",
    "print('Training accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09203006050365803\n",
      "Test accuracy: 0.9815291670793305\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47117 samples, validate on 20194 samples\n",
      "Epoch 1/5\n",
      "47117/47117 [==============================] - 47s 1000us/step - loss: 0.0502 - acc: 0.9793 - val_loss: 0.0242 - val_acc: 0.9880\n",
      "Epoch 2/5\n",
      "47117/47117 [==============================] - 48s 1ms/step - loss: 0.0206 - acc: 0.9897 - val_loss: 0.0190 - val_acc: 0.9917\n",
      "Epoch 3/5\n",
      "47117/47117 [==============================] - 43s 910us/step - loss: 0.0165 - acc: 0.9923 - val_loss: 0.0184 - val_acc: 0.9914\n",
      "Epoch 4/5\n",
      "47117/47117 [==============================] - 45s 945us/step - loss: 0.0123 - acc: 0.9946 - val_loss: 0.0176 - val_acc: 0.9928\n",
      "Epoch 5/5\n",
      "47117/47117 [==============================] - 44s 927us/step - loss: 0.0090 - acc: 0.9962 - val_loss: 0.0225 - val_acc: 0.9910\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling2D,Flatten\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
    "model2.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling1D(pool_size=4))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_log = model2.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.010063560576731764\n",
      "Training accuracy: 0.9957764713373093\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(X_train, Y_train, verbose=0)\n",
    "print('Training loss:', score[0]) \n",
    "print('Training accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.022466428220047248\n",
      "Test accuracy: 0.9909874220065366\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Compare Two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_rnn = model1.predict(X_test).ravel()\n",
    "fpr_rnn, tpr_rnn, thresholds_rnn = roc_curve(Y_test, y_pred_rnn)\n",
    "\n",
    "y_pred_cnn = model2.predict(X_test).ravel()\n",
    "fpr_cnn, tpr_cnn, thresholds_cnn = roc_curve(Y_test, y_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_rnn = auc(fpr_rnn, tpr_rnn)\n",
    "auc_cnn = auc(fpr_cnn, tpr_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rnn, tpr_rnn, label='RNN (AUC = {:.3f})'.format(auc_rnn))\n",
    "plt.plot(fpr_cnn, tpr_cnn, label='CNN (AUC = {:.3f})'.format(auc_cnn))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
